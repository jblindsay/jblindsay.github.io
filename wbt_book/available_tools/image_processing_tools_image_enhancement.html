<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Image enchancement - WhiteboxTools User Manual</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
        <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:500" rel="stylesheet" type="text/css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body class="light">
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../";
            var default_theme = "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { } 
            if (theme === null || theme === undefined) { theme = default_theme; }
            document.body.className = theme;
            document.querySelector('html').className = theme + ' js';
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <ol class="chapter"><li class="affix"><a href="../preface.html">Preface</a></li><li><a href="../intro.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li><a href="../install.html"><strong aria-hidden="true">2.</strong> Setting Up WhiteboxTools</a></li><li><a href="../using_whiteboxtools.html"><strong aria-hidden="true">3.</strong> Using WhiteboxTools</a></li><li><ol class="section"><li><a href="../python_scripting/scripting.html"><strong aria-hidden="true">3.1.</strong> Interfacing with Python</a></li><li><ol class="section"><li><a href="../python_scripting/using_whitebox_tools.html"><strong aria-hidden="true">3.1.1.</strong> Using whitebox_tools.py</a></li><li><a href="../python_scripting/tool_output.html"><strong aria-hidden="true">3.1.2.</strong> Handling tool output</a></li><li><a href="../python_scripting/additional_functions.html"><strong aria-hidden="true">3.1.3.</strong> Additional functions</a></li><li><a href="../python_scripting/example.html"><strong aria-hidden="true">3.1.4.</strong> An example Python project</a></li></ol></li><li><a href="../r_interface.html"><strong aria-hidden="true">3.2.</strong> Interfacing with R</a></li><li><a href="../whitebox_tools_runner.html"><strong aria-hidden="true">3.3.</strong> WhiteboxTools Runner</a></li><li><a href="../qgis_plugin.html"><strong aria-hidden="true">3.4.</strong> QGIS plugin</a></li><li><a href="../arcgis_plugin.html"><strong aria-hidden="true">3.5.</strong> ArcGIS plugin</a></li><li><a href="../command_prompt.html"><strong aria-hidden="true">3.6.</strong> Command-line interface</a></li></ol></li><li><a href="../available_tools/index.html"><strong aria-hidden="true">4.</strong> Tools Reference</a></li><li><ol class="section"><li><a href="../available_tools/data_tools.html"><strong aria-hidden="true">4.1.</strong> Data tools</a></li><li><a href="../available_tools/geomorphometric_analysis.html"><strong aria-hidden="true">4.2.</strong> Geomorphometric analysis</a></li><li><a href="../available_tools/gis_analysis.html"><strong aria-hidden="true">4.3.</strong> GIS analysis</a></li><li><ol class="section"><li><a href="../available_tools/gis_analysis_distance_tools.html"><strong aria-hidden="true">4.3.1.</strong> Distance tools</a></li><li><a href="../available_tools/gis_analysis_overlay_tools.html"><strong aria-hidden="true">4.3.2.</strong> Overlay tools</a></li><li><a href="../available_tools/gis_analysis_patch_shape_tools.html"><strong aria-hidden="true">4.3.3.</strong> Patch shape tools</a></li></ol></li><li><a href="../available_tools/hydrological_analysis.html"><strong aria-hidden="true">4.4.</strong> Hydrological analysis</a></li><li><a href="../available_tools/image_processing_tools.html"><strong aria-hidden="true">4.5.</strong> Image processing tools</a></li><li><ol class="section"><li><a href="../available_tools/image_processing_tools_filters.html"><strong aria-hidden="true">4.5.1.</strong> Filters</a></li><li><a href="../available_tools/image_processing_tools_image_enhancement.html" class="active"><strong aria-hidden="true">4.5.2.</strong> Image enchancement</a></li></ol></li><li><a href="../available_tools/lidar_tools.html"><strong aria-hidden="true">4.6.</strong> LiDAR tools</a></li><li><a href="../available_tools/mathand_stats_tools.html"><strong aria-hidden="true">4.7.</strong> Mathematical and statistical analysis</a></li><li><a href="../available_tools/stream_network_analysis.html"><strong aria-hidden="true">4.8.</strong> Stream network analysis</a></li></ol></li><li><a href="../tutorials/index.html"><strong aria-hidden="true">5.</strong> Tutorials</a></li><li><ol class="section"><li><a href="../tutorials/mosaic.html"><strong aria-hidden="true">5.1.</strong> How can I mosaic hundreds of rasters?</a></li><li><a href="../tutorials/lidar.html"><strong aria-hidden="true">5.2.</strong> Processing LiDAR data</a></li></ol></li><li><a href="../supported_formats.html"><strong aria-hidden="true">6.</strong> Supported Data Formats</a></li><li><a href="../contributing.html"><strong aria-hidden="true">7.</strong> Contributing and Reporting Bugs</a></li><li><a href="../limitations.html"><strong aria-hidden="true">8.</strong> Limitations</a></li><li><a href="../license.html"><strong aria-hidden="true">9.</strong> License</a></li><li><a href="../faq.html"><strong aria-hidden="true">10.</strong> Frequently Asked Questions</a></li><li><a href="../tool_index.html"><strong aria-hidden="true">11.</strong> Tool Index</a></li></ol>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar" class="menu-bar">
                    <div id="menu-bar-sticky-container">
                        <div class="left-buttons">
                            <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                                <i class="fa fa-bars"></i>
                            </button>
                            <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                                <i class="fa fa-paint-brush"></i>
                            </button>
                            <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                                <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                            </ul>
                            
                            <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                                <i class="fa fa-search"></i>
                            </button>
                            
                        </div>

                        <h1 class="menu-title">WhiteboxTools User Manual</h1> 

                        <div class="right-buttons">
                            <a href="../print.html" title="Print this book" aria-label="Print this book">
                                <i id="print-button" class="fa fa-print"></i>
                            </a>
                            
                        </div>
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <a class="header" href="#image-processing-tools--image-enhancement" id="image-processing-tools--image-enhancement"><h1>Image Processing Tools → Image Enhancement</h1></a>
<ul>
<li><a href="#BalanceContrastEnhancement">BalanceContrastEnhancement</a></li>
<li><a href="#CorrectVignetting">CorrectVignetting</a></li>
<li><a href="#DirectDecorrelationStretch">DirectDecorrelationStretch</a></li>
<li><a href="#GammaCorrection">GammaCorrection</a></li>
<li><a href="#GaussianContrastStretch">GaussianContrastStretch</a></li>
<li><a href="#HistogramEqualization">HistogramEqualization</a></li>
<li><a href="#HistogramMatching">HistogramMatching</a></li>
<li><a href="#HistogramMatchingTwoImages">HistogramMatchingTwoImages</a></li>
<li><a href="#MinMaxContrastStretch">MinMaxContrastStretch</a></li>
<li><a href="#PanchromaticSharpening">PanchromaticSharpening</a></li>
<li><a href="#PercentageContrastStretch">PercentageContrastStretch</a></li>
<li><a href="#SigmoidalContrastStretch">SigmoidalContrastStretch</a></li>
<li><a href="#StandardDeviationContrastStretch">StandardDeviationContrastStretch</a></li>
</ul>
<p><a name="BalanceContrastEnhancement"></a></p>
<a class="header" href="#balancecontrastenhancement" id="balancecontrastenhancement"><h1>BalanceContrastEnhancement</h1></a>
<p>This tool can be used to reduce colour bias in a colour composite image based on the
technique described by Liu (1991). Colour bias is a common phenomena with colour images
derived from multispectral imagery, whereby a higher average brightness value in one
band results in over-representation of that band in the colour composite. The tool
essentially applies a parabolic stretch to each of the three bands in a user specified
RGB colour composite, forcing the histograms of each band to have the same minimum,
maximum, and average values while maintaining their overall histogram shape. For greater
detail on the operation of the tool, please see Liu (1991). Aside from the names of the
input and output colour composite images, the user must also set the value of E, the
desired output band mean, where 20 &lt; E &lt; 235.</p>
<p><em>Reference</em>:</p>
<p>Liu, J.G. (1991) Balance contrast enhancement technique and its application in image
colour composition. <em>International Journal of Remote Sensing</em>, 12:10.</p>
<p><em>See Also</em>:</p>
<p><a href="./image_processing_tools_image_enhancement.html#directdecorrelationstretch"><strong>DirectDecorrelationStretch</strong></a>, <a href="./image_processing_tools_image_enhancement.html#histogrammatching"><strong>HistogramMatching</strong></a>, <a href="./image_processing_tools_image_enhancement.html#histogrammatchingtwoimages"><strong>HistogramMatchingTwoImages</strong></a>, <a href="./image_processing_tools_image_enhancement.html#histogramequalization"><strong>HistogramEqualization</strong></a>, <a href="./image_processing_tools_image_enhancement.html#gaussiancontraststretch"><strong>GaussianContrastStretch</strong></a></p>
<p><em>Parameters</em>:</p>
<table><thead><tr><th><strong>Flag</strong>            </th><th>  <strong>Description</strong></th></tr></thead><tbody>
<tr><td>-i, --input        </td><td> Input colour composite image file</td></tr>
<tr><td>-o, --output       </td><td> Output raster file</td></tr>
<tr><td>--band_mean        </td><td> Band mean value</td></tr>
</tbody></table>
<p><em>Python function</em>:</p>
<pre><code class="language-python">wbt.balance_contrast_enhancement(
    i, 
    output, 
    band_mean=100.0, 
    callback=default_callback
)
</code></pre>
<p><em>Command-line Interface</em>:</p>
<pre><code>&gt;&gt;./whitebox_tools -r=BalanceContrastEnhancement -v ^
--wd=&quot;/path/to/data/&quot; --input=image.tif -o=output.tif ^
--band_mean=120 
</code></pre>
<p><a href="https://github.com/jblindsay/whitebox-tools//tree/master/src/tools/image_analysis/balance_contrast_enhancement.rs">Source code on GitHub</a></p>
<p><em>Author</em>: Dr. John Lindsay</p>
<p><em>Created</em>: 19/07/2017</p>
<p><em>Last Modified</em>: 13/10/2018</p>
<p><a name="CorrectVignetting"></a></p>
<a class="header" href="#correctvignetting" id="correctvignetting"><h1>CorrectVignetting</h1></a>
<p>This tool can be used to reduce vignetting within an image. Vignetting refers to the
reducuction of image brightness away from the image centre (i.e. the principal point).
Vignetting is a radiometric distortion resulting from lens characteristics. The
algorithm calculates the brightness value in the output image (BVout) as:</p>
<p>BVout = BVin / [cos^n(arctan(d / f))]</p>
<p>Where d is the photo-distance from the principal point in millimetres, f is the focal
length of the camera, in millimeters, and n is a user-specified parameter. Pixel
distances are converted to photo-distances (in millimetres) using the specified
image width, i.e. distance between left and right edges (mm). For many cameras, 4.0
is an appropriate value of the n parameter. A second pass of the image is used to
rescale the output image so that it possesses the same minimum and maximum values as
the input image.</p>
<p>If an RGB image is input, the analysis will be performed on the intensity component
of the HSI transform.</p>
<p><em>Parameters</em>:</p>
<table><thead><tr><th><strong>Flag</strong>            </th><th>  <strong>Description</strong></th></tr></thead><tbody>
<tr><td>-i, --input        </td><td> Input raster file</td></tr>
<tr><td>--pp               </td><td> Input principal point file</td></tr>
<tr><td>-o, --output       </td><td> Output raster file</td></tr>
<tr><td>--focal_length     </td><td> Camera focal length, in millimeters</td></tr>
<tr><td>--image_width      </td><td> Distance between photograph edges, in millimeters</td></tr>
<tr><td>-n                  </td><td> The 'n' parameter</td></tr>
</tbody></table>
<p><em>Python function</em>:</p>
<pre><code class="language-python">wbt.correct_vignetting(
    i, 
    pp, 
    output, 
    focal_length=304.8, 
    image_width=228.6, 
    n=4.0, 
    callback=default_callback
)
</code></pre>
<p><em>Command-line Interface</em>:</p>
<pre><code>&gt;&gt;./whitebox_tools -r=CorrectVignetting -v ^
--wd=&quot;/path/to/data/&quot; -i=input.tif --pp=princ_pt.shp ^
-o=output.tif --focal_length=304.8 --image_width=228.6 ^
-n=4.0 
</code></pre>
<p><a href="https://github.com/jblindsay/whitebox-tools//tree/master/src/tools/image_analysis/correct_vignetting.rs">Source code on GitHub</a></p>
<p><em>Author</em>: Dr. John Lindsay</p>
<p><em>Created</em>: 24/04/2018</p>
<p><em>Last Modified</em>: 22/10/2019</p>
<p><a name="DirectDecorrelationStretch"></a></p>
<a class="header" href="#directdecorrelationstretch" id="directdecorrelationstretch"><h1>DirectDecorrelationStretch</h1></a>
<p>The Direct Decorrelation Stretch (DDS) is a simple type of saturation stretch. The stretch is
applied to a colour composite image and is used to improve the saturation, or colourfulness,
of the image. The DDS operates by reducing the achromatic (grey) component of a pixel's colour
by a scale factor (<em>k</em>), such that the red (r), green (g), and blue (b) components of the output
colour are defined as:</p>
<p>r<sub><em>k</em></sub> = r - <em>k</em> min(r, g, b)</p>
<p>g<sub><em>k</em></sub> = g - <em>k</em> min(r, g, b)</p>
<p>b<sub><em>k</em></sub> = b - <em>k</em> min(r, g, b)</p>
<p>The achromatic factor (<em>k</em>) can range between 0 (no effect) and 1 (full saturation stretch),
although typical values range from 0.3 to 0.7. A linear stretch is used afterwards to adjust
overall image brightness. Liu and Moore (1996) recommend applying a colour balance stretch,
such as <a href="./image_processing_tools_image_enhancement.html#balancecontrastenhancement"><strong>BalanceContrastEnhancement</strong></a> before using the DDS.</p>
<p><em>Reference</em>:</p>
<p>Liu, J.G., and Moore, J. (1996) Direct decorrelation stretch technique for RGB colour composition.
International Journal of Remote Sensing, 17:5, 1005-1018.</p>
<p><em>See Also</em>:</p>
<p><a href="./image_processing_tools.html#createcolourcomposite"><strong>CreateColourComposite</strong></a>, <a href="./image_processing_tools_image_enhancement.html#balancecontrastenhancement"><strong>BalanceContrastEnhancement</strong></a></p>
<p><em>Parameters</em>:</p>
<table><thead><tr><th><strong>Flag</strong>            </th><th>  <strong>Description</strong></th></tr></thead><tbody>
<tr><td>-i, --input        </td><td> Input colour composite image file</td></tr>
<tr><td>-o, --output       </td><td> Output raster file</td></tr>
<tr><td>-k                  </td><td> Achromatic factor (k) ranges between 0 (no effect) and 1 (full saturation stretch), although typical values range from 0.3 to 0.7</td></tr>
<tr><td>--clip             </td><td> Optional percent to clip the upper tail by during the stretch</td></tr>
</tbody></table>
<p><em>Python function</em>:</p>
<pre><code class="language-python">wbt.direct_decorrelation_stretch(
    i, 
    output, 
    k=0.5, 
    clip=1.0, 
    callback=default_callback
)
</code></pre>
<p><em>Command-line Interface</em>:</p>
<pre><code>&gt;&gt;./whitebox_tools -r=DirectDecorrelationStretch -v ^
--wd=&quot;/path/to/data/&quot; --input=image.tif -o=output.tif -k=0.4 
</code></pre>
<p><a href="https://github.com/jblindsay/whitebox-tools//tree/master/src/tools/image_analysis/direct_decorrelation_stretch.rs">Source code on GitHub</a></p>
<p><em>Author</em>: Dr. John Lindsay</p>
<p><em>Created</em>: 21/07/2017</p>
<p><em>Last Modified</em>: 13/10/2018</p>
<p><a name="GammaCorrection"></a></p>
<a class="header" href="#gammacorrection" id="gammacorrection"><h1>GammaCorrection</h1></a>
<p>This tool performs a gamma colour correction transform on an input image (<code>--input</code>), such that each
input pixel value (z<sub>in</sub><sup>) is mapped to the corresponding output value (z<sub>out</sub>) as:</p>
<blockquote>
<p>z<sub>out</sub> = z<sub>in</sub><sup><code>gamma</code></sup></p>
</blockquote>
<p>The user must specify the value of the <code>gamma</code> parameter. The input image may be of either a greyscale or RGB colour
composite data type.</p>
<p><em>Parameters</em>:</p>
<table><thead><tr><th><strong>Flag</strong>            </th><th>  <strong>Description</strong></th></tr></thead><tbody>
<tr><td>-i, --input        </td><td> Input raster file</td></tr>
<tr><td>-o, --output       </td><td> Output raster file</td></tr>
<tr><td>--gamma            </td><td> Gamma value</td></tr>
</tbody></table>
<p><em>Python function</em>:</p>
<pre><code class="language-python">wbt.gamma_correction(
    i, 
    output, 
    gamma=0.5, 
    callback=default_callback
)
</code></pre>
<p><em>Command-line Interface</em>:</p>
<pre><code>&gt;&gt;./whitebox_tools -r=GammaCorrection -v ^
--wd=&quot;/path/to/data/&quot; -i=input.tif -o=output.tif --gamma=0.5 
</code></pre>
<p><a href="https://github.com/jblindsay/whitebox-tools//tree/master/src/tools/image_analysis/gamma_correction.rs">Source code on GitHub</a></p>
<p><em>Author</em>: Dr. John Lindsay</p>
<p><em>Created</em>: 13/07/2017</p>
<p><em>Last Modified</em>: 22/10/2019</p>
<p><a name="GaussianContrastStretch"></a></p>
<a class="header" href="#gaussiancontraststretch" id="gaussiancontraststretch"><h1>GaussianContrastStretch</h1></a>
<p>This tool performs a Gaussian stretch on a raster image. The observed histogram of the input image is fitted
to a Gaussian histogram, i.e. normal distribution. A histogram matching technique is used to map the values from
the input image onto the output Gaussian distribution. The user must the number of tones (<code>--num_tones</code>) used in the
output image.</p>
<p>This tool is related to the more general <a href="./image_processing_tools_image_enhancement.html#histogrammatching"><strong>HistogramMatching</strong></a> tool, which can be used to fit any frequency distribution
to an input image, and other contrast enhancement tools such as <a href="./image_processing_tools_image_enhancement.html#histogramequalization"><strong>HistogramEqualization</strong></a>, <a href="./image_processing_tools_image_enhancement.html#minmaxcontraststretch"><strong>MinMaxContrastStretch</strong></a>,
<a href="./image_processing_tools_image_enhancement.html#percentagecontraststretch"><strong>PercentageContrastStretch</strong></a>, <a href="./image_processing_tools_image_enhancement.html#sigmoidalcontraststretch"><strong>SigmoidalContrastStretch</strong></a>, and <a href="./image_processing_tools_image_enhancement.html#standarddeviationcontraststretch"><strong>StandardDeviationContrastStretch</strong></a>.</p>
<p><em>See Also</em>:</p>
<p><a href="./image_processing_tools_image_enhancement.html#histogramequalization"><strong>HistogramEqualization</strong></a>, <a href="./image_processing_tools_image_enhancement.html#minmaxcontraststretch"><strong>MinMaxContrastStretch</strong></a>, <a href="./image_processing_tools_image_enhancement.html#percentagecontraststretch"><strong>PercentageContrastStretch</strong></a>, <a href="./image_processing_tools_image_enhancement.html#sigmoidalcontraststretch"><strong>SigmoidalContrastStretch</strong></a>,
<a href="./image_processing_tools_image_enhancement.html#standarddeviationcontraststretch"><strong>StandardDeviationContrastStretch</strong></a>, <a href="./image_processing_tools_image_enhancement.html#histogrammatching"><strong>HistogramMatching</strong></a></p>
<p><em>Parameters</em>:</p>
<table><thead><tr><th><strong>Flag</strong>            </th><th>  <strong>Description</strong></th></tr></thead><tbody>
<tr><td>-i, --input        </td><td> Input raster file</td></tr>
<tr><td>-o, --output       </td><td> Output raster file</td></tr>
<tr><td>--num_tones        </td><td> Number of tones in the output image</td></tr>
</tbody></table>
<p><em>Python function</em>:</p>
<pre><code class="language-python">wbt.gaussian_contrast_stretch(
    i, 
    output, 
    num_tones=256, 
    callback=default_callback
)
</code></pre>
<p><em>Command-line Interface</em>:</p>
<pre><code>&gt;&gt;./whitebox_tools -r=GaussianContrastStretch -v ^
--wd=&quot;/path/to/data/&quot; -i=input.tif -o=output.tif ^
--num_tones=1024 
</code></pre>
<p><a href="https://github.com/jblindsay/whitebox-tools//tree/master/src/tools/image_analysis/gaussian_contrast_stretch.rs">Source code on GitHub</a></p>
<p><em>Author</em>: Dr. John Lindsay</p>
<p><em>Created</em>: 21/05/2018</p>
<p><em>Last Modified</em>: 22/10/2019</p>
<p><a name="HistogramEqualization"></a></p>
<a class="header" href="#histogramequalization" id="histogramequalization"><h1>HistogramEqualization</h1></a>
<p>This tool alters the cumulative distribution function (CDF) of a raster image to match,
as closely as possible, the CDF of a uniform distribution. Histogram equalization works
by first calculating the histogram of the input image. This input histogram is then
converted into a CDF. Each grid cell value in the input image is then mapped to the
corresponding value in the uniform distribution's CDF that has an equivalent (or as close
as possible) cumulative probability value. Histogram equalization provides a very effective
means of performing image contrast adjustment in an efficient manner with little need for
human input.</p>
<p>The user must specify the name of the input image to perform histogram equalization on.
The user must also specify the number of tones, corresponding to the number
of histogram bins used in the analysis.</p>
<p><a href="./image_processing_tools_image_enhancement.html#histogramequalization"><strong>HistogramEqualization</strong></a> is related to the <a href="./image_processing_tools_image_enhancement.html#histogrammatchingtwoimages"><strong>HistogramMatchingTwoImages</strong></a> tool (used when an image's
CDF is to be matched to a reference CDF derived from a reference image). Similarly, <a href="./image_processing_tools_image_enhancement.html#histogrammatching"><strong>HistogramMatching</strong></a>,
and <a href="./image_processing_tools_image_enhancement.html#gaussiancontraststretch"><strong>GaussianContrastStretch</strong></a> are similarly related tools frequently used for image contrast
adjustment, where the reference CDFs are uniform and Gaussian (normal) respectively.</p>
<p><strong>Notes</strong>:</p>
<ul>
<li>The algorithm can introduces gaps in the histograms (steps in the CDF). This is to be expected because
the histogram is being distorted. This is more prevalent for integer-level images.</li>
<li>Histogram equalization is not appropriate for images containing categorical (class) data.</li>
</ul>
<p><em>See Also</em>:</p>
<p><a href="./image_processing_tools_image_enhancement.html#histogrammatching"><strong>HistogramMatching</strong></a>, <a href="./image_processing_tools_image_enhancement.html#histogrammatchingtwoimages"><strong>HistogramMatchingTwoImages</strong></a>, <a href="./image_processing_tools_image_enhancement.html#gaussiancontraststretch"><strong>GaussianContrastStretch</strong></a></p>
<p><em>Parameters</em>:</p>
<table><thead><tr><th><strong>Flag</strong>            </th><th>  <strong>Description</strong></th></tr></thead><tbody>
<tr><td>-i, --input        </td><td> Input raster file</td></tr>
<tr><td>-o, --output       </td><td> Output raster file</td></tr>
<tr><td>--num_tones        </td><td> Number of tones in the output image</td></tr>
</tbody></table>
<p><em>Python function</em>:</p>
<pre><code class="language-python">wbt.histogram_equalization(
    i, 
    output, 
    num_tones=256, 
    callback=default_callback
)
</code></pre>
<p><em>Command-line Interface</em>:</p>
<pre><code>&gt;&gt;./whitebox_tools -r=HistogramEqualization -v ^
--wd=&quot;/path/to/data/&quot; -i=input.tif -o=output.tif ^
--num_tones=1024 
</code></pre>
<p><a href="https://github.com/jblindsay/whitebox-tools//tree/master/src/tools/image_analysis/histogram_equalization.rs">Source code on GitHub</a></p>
<p><em>Author</em>: Dr. John Lindsay</p>
<p><em>Created</em>: 26/08/2017</p>
<p><em>Last Modified</em>: 22/10/2019</p>
<p><a name="HistogramMatching"></a></p>
<a class="header" href="#histogrammatching" id="histogrammatching"><h1>HistogramMatching</h1></a>
<p>This tool alters the cumulative distribution function (CDF) of a raster image to match,
as closely as possible, the CDF of a reference histogram. Histogram matching works by
first calculating the histogram of the input image. This input histogram and reference
histograms are each then converted into CDFs. Each grid cell value in the input image
is then mapped to the corresponding value in the reference CDF that has an equivalent
(or as close as possible) cumulative probability value. Histogram matching provides
the most flexible means of performing image contrast adjustment.</p>
<p>The reference histogram must be specified to the tool in the form of a text file (.txt),
provided using the <code>--histo_file</code> flag. This file must contain two columns (delimited by
a tab, space, comma, colon, or semicolon) where the first column contains the x value
(i.e. the values that will be assigned to the grid cells in the output image) and the second
column contains the frequency or probability. Note that 1) the file must not contain a
header row, 2) each x value/frequency pair must be on a separate row, and 3) the
frequency/probability must not be cumulative (i.e. the file must contain the histogram and
not the CDF). The CDF will be computed for the reference histogram automatically by the tool.
It is possible to create this type of histogram using the wide range of distribution tools
available in most spreadsheet programs (e.g. Excel or LibreOffice's Calc program). You must
save the file as a text-only (ASCII) file.</p>
<p><a href="./image_processing_tools_image_enhancement.html#histogrammatching"><strong>HistogramMatching</strong></a> is related to the <a href="./image_processing_tools_image_enhancement.html#histogrammatchingtwoimages"><strong>HistogramMatchingTwoImages</strong></a> tool, which can be used
when a reference CDF can be derived from a reference image. <a href="./image_processing_tools_image_enhancement.html#histogramequalization"><strong>HistogramEqualization</strong></a> and
<a href="./image_processing_tools_image_enhancement.html#gaussiancontraststretch"><strong>GaussianContrastStretch</strong></a> are similarly related tools frequently used for image contrast
adjustment, where the reference CDFs are uniform and Gaussian (normal) respectively.</p>
<p><strong>Notes:</strong></p>
<ul>
<li>The algorithm can introduces gaps in the histograms (steps in the CDF). This is to be expected
because the histogram is being distorted. This is more prevalent for integer-level images.</li>
<li>Histogram matching is not appropriate for images containing categorical (class) data.</li>
<li>This tool is not intended for images containing RGB data. If this is the case, the colour
channels should be split using the <a href="./image_processing_tools.html#splitcolourcomposite"><strong>SplitColourComposite</strong></a> tool.</li>
</ul>
<p><em>See Also</em>:</p>
<p><a href="./image_processing_tools_image_enhancement.html#histogrammatchingtwoimages"><strong>HistogramMatchingTwoImages</strong></a>, <a href="./image_processing_tools_image_enhancement.html#histogramequalization"><strong>HistogramEqualization</strong></a>, <a href="./image_processing_tools_image_enhancement.html#gaussiancontraststretch"><strong>GaussianContrastStretch</strong></a>, <a href="./image_processing_tools.html#splitcolourcomposite"><strong>SplitColourComposite</strong></a></p>
<p><em>Parameters</em>:</p>
<table><thead><tr><th><strong>Flag</strong>            </th><th>  <strong>Description</strong></th></tr></thead><tbody>
<tr><td>-i, --input        </td><td> Input raster file</td></tr>
<tr><td>--histo_file       </td><td> Input reference probability distribution function (pdf) text file</td></tr>
<tr><td>-o, --output       </td><td> Output raster file</td></tr>
</tbody></table>
<p><em>Python function</em>:</p>
<pre><code class="language-python">wbt.histogram_matching(
    i, 
    histo_file, 
    output, 
    callback=default_callback
)
</code></pre>
<p><em>Command-line Interface</em>:</p>
<pre><code>&gt;&gt;./whitebox_tools -r=HistogramMatching -v ^
--wd=&quot;/path/to/data/&quot; -i=input1.tif --histo_file=histo.txt ^
-o=output.tif 
</code></pre>
<p><a href="https://github.com/jblindsay/whitebox-tools//tree/master/src/tools/image_analysis/histogram_matching.rs">Source code on GitHub</a></p>
<p><em>Author</em>: Dr. John Lindsay</p>
<p><em>Created</em>: 14/09/2017</p>
<p><em>Last Modified</em>: 13/10/2018</p>
<p><a name="HistogramMatchingTwoImages"></a></p>
<a class="header" href="#histogrammatchingtwoimages" id="histogrammatchingtwoimages"><h1>HistogramMatchingTwoImages</h1></a>
<p>This tool alters the cumulative distribution function (CDF) of a raster image to match, as closely
as possible, the CDF of a reference image. Histogram matching works by first calculating the
histograms of the input image (i.e. the image to be adjusted) and the reference image. These
histograms are then converted into CDFs. Each grid cell value in the input image is then mapped
to the corresponding value in the reference CDF that has the an equivalent (or as close as
possible) cumulative probability value. A common application of this is to match the images from
two sensors with slightly different responses, or images from the same sensor, but the sensor's
response is known to change over time.The size of the two images (rows and columns) do not need
to be the same, nor do they need to be geographically overlapping.</p>
<p><a href="./image_processing_tools_image_enhancement.html#histogrammatchingtwoimages"><strong>HistogramMatchingTwoImages</strong></a> is related to the <a href="./image_processing_tools_image_enhancement.html#histogrammatching"><strong>HistogramMatching</strong></a> tool, which can be used
when a reference CDF is used directly rather than deriving it from a reference image.
<a href="./image_processing_tools_image_enhancement.html#histogramequalization"><strong>HistogramEqualization</strong></a> and <a href="./image_processing_tools_image_enhancement.html#gaussiancontraststretch"><strong>GaussianContrastStretch</strong></a> are similarly related tools, where the
reference CDFs are uniform and Gaussian (normal) respectively.</p>
<p>The algorithm may introduces gaps in the histograms (steps in the CDF). This is to be expected
because the histograms are being distorted. This is more prevalent for integer-level images.
Histogram matching is not appropriate for images containing categorical (class) data. It is also
not intended for images containing RGB data, in which case, the colour channels should be split
using the <a href="./image_processing_tools.html#splitcolourcomposite"><strong>SplitColourComposite</strong></a> tool.</p>
<p><em>See Also</em>:</p>
<p><a href="./image_processing_tools_image_enhancement.html#histogrammatching"><strong>HistogramMatching</strong></a>, <a href="./image_processing_tools_image_enhancement.html#histogramequalization"><strong>HistogramEqualization</strong></a>, <a href="./image_processing_tools_image_enhancement.html#gaussiancontraststretch"><strong>GaussianContrastStretch</strong></a>, <a href="./image_processing_tools.html#splitcolourcomposite"><strong>SplitColourComposite</strong></a></p>
<p><em>Parameters</em>:</p>
<table><thead><tr><th><strong>Flag</strong>            </th><th>  <strong>Description</strong></th></tr></thead><tbody>
<tr><td>--i1, --input1    </td><td> Input raster file to modify</td></tr>
<tr><td>--i2, --input2    </td><td> Input reference raster file</td></tr>
<tr><td>-o, --output       </td><td> Output raster file</td></tr>
</tbody></table>
<p><em>Python function</em>:</p>
<pre><code class="language-python">wbt.histogram_matching_two_images(
    input1, 
    input2, 
    output, 
    callback=default_callback
)
</code></pre>
<p><em>Command-line Interface</em>:</p>
<pre><code>&gt;&gt;./whitebox_tools -r=HistogramMatchingTwoImages -v ^
--wd=&quot;/path/to/data/&quot; --i1=input1.tif --i2=input2.tif ^
-o=output.tif 
</code></pre>
<p><a href="https://github.com/jblindsay/whitebox-tools//tree/master/src/tools/image_analysis/histogram_matching_two_images.rs">Source code on GitHub</a></p>
<p><em>Author</em>: Dr. John Lindsay</p>
<p><em>Created</em>: 31/08/2017</p>
<p><em>Last Modified</em>: 13/10/2018</p>
<p><a name="MinMaxContrastStretch"></a></p>
<a class="header" href="#minmaxcontraststretch" id="minmaxcontraststretch"><h1>MinMaxContrastStretch</h1></a>
<p>This tool performs a minimum-maximum contrast stretch on a raster image. This operation maps each grid cell
value in the input raster image (z) onto a new scale that ranges from the user-specified lower-tail clip
value (<code>min_val</code>) to the upper-tail clip value (<code>max_val</code>), with the specified number of tonal values
(<code>num_tones</code>), such that:</p>
<blockquote>
<p>z<sub>out</sub> = ((z<sub>in</sub> – min_val)/(max_val – min_val)) x num_tones</p>
</blockquote>
<p>where z<sub>out</sub> is the output value. Notice that any values in the input image that are less than
<code>min_val</code> are assigned a value of <code>min_val</code> in the output image. Similarly, any input values greater than
<code>max_val</code> are assigned a value of <code>max_val</code> in the output image.</p>
<p>This is a type of linear contrast stretch with saturation at the tails of the frequency distribution. This is
the same kind of stretch that is used to display raster type data on the fly in many GIS software packages,
such that the lower and upper tail values are set using the minimum and maximum display values and the number
of tonal values is determined by the number of palette entries.</p>
<p><em>See Also</em>:</p>
<p><a href="./image_processing_tools_image_enhancement.html#gaussiancontraststretch"><strong>GaussianContrastStretch</strong></a>, <a href="./image_processing_tools_image_enhancement.html#histogramequalization"><strong>HistogramEqualization</strong></a>, <a href="./image_processing_tools_image_enhancement.html#percentagecontraststretch"><strong>PercentageContrastStretch</strong></a>, <a href="./image_processing_tools_image_enhancement.html#sigmoidalcontraststretch"><strong>SigmoidalContrastStretch</strong></a>,
<a href="./image_processing_tools_image_enhancement.html#standarddeviationcontraststretch"><strong>StandardDeviationContrastStretch</strong></a></p>
<p><em>Parameters</em>:</p>
<table><thead><tr><th><strong>Flag</strong>            </th><th>  <strong>Description</strong></th></tr></thead><tbody>
<tr><td>-i, --input        </td><td> Input raster file</td></tr>
<tr><td>-o, --output       </td><td> Output raster file</td></tr>
<tr><td>--min_val          </td><td> Lower tail clip value</td></tr>
<tr><td>--max_val          </td><td> Upper tail clip value</td></tr>
<tr><td>--num_tones        </td><td> Number of tones in the output image</td></tr>
</tbody></table>
<p><em>Python function</em>:</p>
<pre><code class="language-python">wbt.min_max_contrast_stretch(
    i, 
    output, 
    min_val, 
    max_val, 
    num_tones=256, 
    callback=default_callback
)
</code></pre>
<p><em>Command-line Interface</em>:</p>
<pre><code>&gt;&gt;./whitebox_tools -r=MinMaxContrastStretch -v ^
--wd=&quot;/path/to/data/&quot; -i=input.tif -o=output.tif ^
--min_val=45.0 --max_val=200.0 --num_tones=1024 
</code></pre>
<p><a href="https://github.com/jblindsay/whitebox-tools//tree/master/src/tools/image_analysis/min_max_contrast_stretch.rs">Source code on GitHub</a></p>
<p><em>Author</em>: Dr. John Lindsay</p>
<p><em>Created</em>: 13/07/2017</p>
<p><em>Last Modified</em>: 22/10/2019</p>
<p><a name="PanchromaticSharpening"></a></p>
<a class="header" href="#panchromaticsharpening" id="panchromaticsharpening"><h1>PanchromaticSharpening</h1></a>
<p>Panchromatic sharpening, or simply pan-sharpening, refers to a range of techniques that can be used to merge
finer spatial resolution panchromatic images with coarser spatial resolution multi-spectral images. The
multi-spectral data provides colour information while the panchromatic image provides improved spatial information.
This procedure is sometimes called image fusion. Jensen (2015) describes panchromatic sharpening in detail.</p>
<p>Whitebox provides two common methods for panchromatic sharpening including the Brovey transformation and the
Intensity-Hue-Saturation (IHS) methods. Both of these techniques provide the best results when the range of
wavelengths detected by the panchromatic image overlap significantly with the wavelength range covered by the
three multi-spectral bands that are used. When this is not the case, the resulting colour composite will likely
have colour properties that are dissimilar to the colour composite generated by the original multispectral images.
For Landsat ETM+ data, the panchromatic band is sensitive to EMR in the range of 0.52-0.90 micrometres. This
corresponds closely to the green (band 2), red (band 3), and near-infrared (band 4).</p>
<p><em>Reference</em>:</p>
<p>Jensen, J. R. (2015). Introductory Digital Image Processing: A Remote Sensing Perspective.</p>
<p><em>See Also</em>:</p>
<p><a href="./image_processing_tools.html#createcolourcomposite"><strong>CreateColourComposite</strong></a></p>
<p><em>Parameters</em>:</p>
<table><thead><tr><th><strong>Flag</strong>            </th><th>  <strong>Description</strong></th></tr></thead><tbody>
<tr><td>--red              </td><td> Input red band image file. Optionally specified if colour-composite not specified</td></tr>
<tr><td>--green            </td><td> Input green band image file. Optionally specified if colour-composite not specified</td></tr>
<tr><td>--blue             </td><td> Input blue band image file. Optionally specified if colour-composite not specified</td></tr>
<tr><td>--composite        </td><td> Input colour-composite image file. Only used if individual bands are not specified</td></tr>
<tr><td>--pan              </td><td> Input panchromatic band file</td></tr>
<tr><td>-o, --output       </td><td> Output colour composite file</td></tr>
<tr><td>--method           </td><td> Options include 'brovey' (default) and 'ihs'</td></tr>
</tbody></table>
<p><em>Python function</em>:</p>
<pre><code class="language-python">wbt.panchromatic_sharpening(
    pan, 
    output, 
    red=None, 
    green=None, 
    blue=None, 
    composite=None, 
    method=&quot;brovey&quot;, 
    callback=default_callback
)
</code></pre>
<p><em>Command-line Interface</em>:</p>
<pre><code>&gt;&gt;./whitebox_tools -r=PanchromaticSharpening -v ^
--wd=&quot;/path/to/data/&quot; --red=red.tif --green=green.tif ^
--blue=blue.tif --pan=pan.tif --output=pan_sharp.tif ^
--method='brovey'
&gt;&gt;./whitebox_tools -r=PanchromaticSharpening ^
-v --wd=&quot;/path/to/data/&quot; --composite=image.tif --pan=pan.tif ^
--output=pan_sharp.tif --method='ihs' 
</code></pre>
<p><a href="https://github.com/jblindsay/whitebox-tools//tree/master/src/tools/image_analysis/pan_sharpening.rs">Source code on GitHub</a></p>
<p><em>Author</em>: Dr. John Lindsay</p>
<p><em>Created</em>: 27/07/2017</p>
<p><em>Last Modified</em>: 11/02/2019</p>
<p><a name="PercentageContrastStretch"></a></p>
<a class="header" href="#percentagecontraststretch" id="percentagecontraststretch"><h1>PercentageContrastStretch</h1></a>
<p>This tool performs a percentage contrast stretch on a raster image. This operation maps each grid cell value
in the input raster image (z<sub>in</sub>) onto a new scale that ranges from a lower-tail clip value (<code>min_val</code>)
to the upper-tail clip value (<code>max_val</code>), with the user-specified number of tonal values (<code>num_tones</code>), such that:</p>
<blockquote>
<p>z<sub>out</sub> = ((z<sub>in</sub> – min_val)/(max_val – min_val)) x num_tones</p>
</blockquote>
<p>where z<sub>out</sub> is the output value. The values of <code>min_val</code> and <code>max_val</code> are determined from the frequency
distribution and the user-specified tail clip value (<code>--clip</code>). For example, if a value of 1% is specified, the tool
will determine the values in the input image for which 1% of the grid cells have a lower value <code>min_val</code> and 1% of
the grid cells have a higher value <code>max_val</code>. The user must also specify which tails (upper, lower, or both) to clip
(<code>--tail</code>).</p>
<p>This is a type of linear contrast stretch with saturation at the tails of the frequency distribution. This is
the same kind of stretch that is used to display raster type data on the fly in many GIS software packages,
such that the lower and upper tail values are set using the minimum and maximum display values and the number
of tonal values is determined by the number of palette entries.</p>
<p><em>See Also</em>:</p>
<p><a href="./image_processing_tools_image_enhancement.html#gaussiancontraststretch"><strong>GaussianContrastStretch</strong></a>, <a href="./image_processing_tools_image_enhancement.html#histogramequalization"><strong>HistogramEqualization</strong></a>, <a href="./image_processing_tools_image_enhancement.html#minmaxcontraststretch"><strong>MinMaxContrastStretch</strong></a>, <a href="./image_processing_tools_image_enhancement.html#sigmoidalcontraststretch"><strong>SigmoidalContrastStretch</strong></a>,
<a href="./image_processing_tools_image_enhancement.html#standarddeviationcontraststretch"><strong>StandardDeviationContrastStretch</strong></a></p>
<p><em>Parameters</em>:</p>
<table><thead><tr><th><strong>Flag</strong>            </th><th>  <strong>Description</strong></th></tr></thead><tbody>
<tr><td>-i, --input        </td><td> Input raster file</td></tr>
<tr><td>-o, --output       </td><td> Output raster file</td></tr>
<tr><td>--clip             </td><td> Optional amount to clip the distribution tails by, in percent</td></tr>
<tr><td>--tail             </td><td> Specified which tails to clip; options include 'upper', 'lower', and 'both' (default is 'both')</td></tr>
<tr><td>--num_tones        </td><td> Number of tones in the output image</td></tr>
</tbody></table>
<p><em>Python function</em>:</p>
<pre><code class="language-python">wbt.percentage_contrast_stretch(
    i, 
    output, 
    clip=1.0, 
    tail=&quot;both&quot;, 
    num_tones=256, 
    callback=default_callback
)
</code></pre>
<p><em>Command-line Interface</em>:</p>
<pre><code>&gt;&gt;./whitebox_tools -r=PercentageContrastStretch -v ^
--wd=&quot;/path/to/data/&quot; -i=input.tif -o=output.tif --clip=2.0 ^
--tail='both' --num_tones=1024 
</code></pre>
<p><a href="https://github.com/jblindsay/whitebox-tools//tree/master/src/tools/image_analysis/percentage_contrast_stretch.rs">Source code on GitHub</a></p>
<p><em>Author</em>: Dr. John Lindsay</p>
<p><em>Created</em>: 13/07/2017</p>
<p><em>Last Modified</em>: 22/10/2019</p>
<p><a name="SigmoidalContrastStretch"></a></p>
<a class="header" href="#sigmoidalcontraststretch" id="sigmoidalcontraststretch"><h1>SigmoidalContrastStretch</h1></a>
<p>This tool performs a sigmoidal stretch on a raster image. This is a transformation where the input image value for a
grid cell (z<sub>in</sub>) is transformed to an output value zout such that:</p>
<blockquote>
<p>z<sub>out</sub> = (1.0 / (1.0 + exp(<em>gain</em>(<em>cutoff</em> - z))) - <em>a</em> ) / <em>b</em> x <em>num_tones</em></p>
</blockquote>
<p>where,</p>
<blockquote>
<p>z = (z<sub>in</sub> - <em>MIN</em>) / <em>RANGE</em>,</p>
</blockquote>
<blockquote>
<p><em>a</em> = 1.0 / (1.0 + exp(<em>gain</em> x <em>cutoff</em>)),</p>
</blockquote>
<blockquote>
<p><em>b</em> = 1.0 / (1.0 + exp(<em>gain</em> x (<em>cutoff</em> - 1.0))) - 1.0 / (1.0 + exp(<em>gain</em> x <em>cutoff</em>)),</p>
</blockquote>
<p><em>MIN</em> and <em>RANGE</em> are the minimum value and data range in the input image respectively and <em>gain</em> and <em>cutoff</em> are
user specified parameters (<code>--gain</code>, <code>--cutoff</code>).</p>
<p>Like all of <em>WhiteboxTools</em>'s contrast enhancement tools, this operation will work on either greyscale or RGB input
images.</p>
<p><em>See Also</em>:</p>
<p><a href="./image_processing_tools_image_enhancement.html#gaussiancontraststretch"><strong>GaussianContrastStretch</strong></a>, <a href="./image_processing_tools_image_enhancement.html#histogramequalization"><strong>HistogramEqualization</strong></a>, <a href="./image_processing_tools_image_enhancement.html#minmaxcontraststretch"><strong>MinMaxContrastStretch</strong></a>,  <a href="./image_processing_tools_image_enhancement.html#percentagecontraststretch"><strong>PercentageContrastStretch</strong></a>,
<a href="./image_processing_tools_image_enhancement.html#standarddeviationcontraststretch"><strong>StandardDeviationContrastStretch</strong></a></p>
<p><em>Parameters</em>:</p>
<table><thead><tr><th><strong>Flag</strong>            </th><th>  <strong>Description</strong></th></tr></thead><tbody>
<tr><td>-i, --input        </td><td> Input raster file</td></tr>
<tr><td>-o, --output       </td><td> Output raster file</td></tr>
<tr><td>--cutoff           </td><td> Cutoff value between 0.0 and 0.95</td></tr>
<tr><td>--gain             </td><td> Gain value</td></tr>
<tr><td>--num_tones        </td><td> Number of tones in the output image</td></tr>
</tbody></table>
<p><em>Python function</em>:</p>
<pre><code class="language-python">wbt.sigmoidal_contrast_stretch(
    i, 
    output, 
    cutoff=0.0, 
    gain=1.0, 
    num_tones=256, 
    callback=default_callback
)
</code></pre>
<p><em>Command-line Interface</em>:</p>
<pre><code>&gt;&gt;./whitebox_tools -r=SigmoidalContrastStretch -v ^
--wd=&quot;/path/to/data/&quot; -i=input.tif -o=output.tif --cutoff=0.1 ^
--gain=2.0 --num_tones=1024 
</code></pre>
<p><a href="https://github.com/jblindsay/whitebox-tools//tree/master/src/tools/image_analysis/sigmoidal_contrast_stretch.rs">Source code on GitHub</a></p>
<p><em>Author</em>: Dr. John Lindsay</p>
<p><em>Created</em>: 13/07/2017</p>
<p><em>Last Modified</em>: 22/10/2019</p>
<p><a name="StandardDeviationContrastStretch"></a></p>
<a class="header" href="#standarddeviationcontraststretch" id="standarddeviationcontraststretch"><h1>StandardDeviationContrastStretch</h1></a>
<p>This tool performs a standard deviation contrast stretch on a raster image. This operation maps each grid cell value
in the input raster image (z<sub>in</sub>) onto a new scale that ranges from a lower-tail clip value (<code>min_val</code>)
to the upper-tail clip value (<code>max_val</code>), with the user-specified number of tonal values (<code>num_tones</code>), such that:</p>
<blockquote>
<p>z<sub>out</sub> = ((z<sub>in</sub> – min_val)/(max_val – min_val)) x num_tones</p>
</blockquote>
<p>where z<sub>out</sub> is the output value. The values of <code>min_val</code> and <code>max_val</code> are determined based on the image
mean and standard deviation. Specifically, the user must specify the number of standard deviations (<code>--clip</code> or
<code>--stdev</code>) to be used in determining the min and max clip values. The tool will then calculate the input image mean
and standard deviation and estimate the clip values from these statistics.</p>
<p>This is the same kind of stretch that is used to display raster type data on the fly in many GIS software packages.</p>
<p><em>See Also</em>:</p>
<p><a href="./image_processing_tools_image_enhancement.html#gaussiancontraststretch"><strong>GaussianContrastStretch</strong></a>, <a href="./image_processing_tools_image_enhancement.html#histogramequalization"><strong>HistogramEqualization</strong></a>, <a href="./image_processing_tools_image_enhancement.html#minmaxcontraststretch"><strong>MinMaxContrastStretch</strong></a>,  <a href="./image_processing_tools_image_enhancement.html#percentagecontraststretch"><strong>PercentageContrastStretch</strong></a>,
<a href="./image_processing_tools_image_enhancement.html#sigmoidalcontraststretch"><strong>SigmoidalContrastStretch</strong></a></p>
<p><em>Parameters</em>:</p>
<table><thead><tr><th><strong>Flag</strong>            </th><th>  <strong>Description</strong></th></tr></thead><tbody>
<tr><td>-i, --input        </td><td> Input raster file</td></tr>
<tr><td>-o, --output       </td><td> Output raster file</td></tr>
<tr><td>--clip, --stdev   </td><td> Standard deviation clip value</td></tr>
<tr><td>--num_tones        </td><td> Number of tones in the output image</td></tr>
</tbody></table>
<p><em>Python function</em>:</p>
<pre><code class="language-python">wbt.standard_deviation_contrast_stretch(
    i, 
    output, 
    stdev=2.0, 
    num_tones=256, 
    callback=default_callback
)
</code></pre>
<p><em>Command-line Interface</em>:</p>
<pre><code>&gt;&gt;./whitebox_tools -r=StandardDeviationContrastStretch -v ^
--wd=&quot;/path/to/data/&quot; -i=input.tif -o=output.tif --stdev=2.0 ^
--num_tones=1024 
</code></pre>
<p><a href="https://github.com/jblindsay/whitebox-tools//tree/master/src/tools/image_analysis/stdev_contrast_stretch.rs">Source code on GitHub</a></p>
<p><em>Author</em>: Dr. John Lindsay</p>
<p><em>Created</em>: 13/07/2017</p>
<p><em>Last Modified</em>: 22/10/2019</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                            <a rel="prev" href="../available_tools/image_processing_tools_filters.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                        

                        
                            <a rel="next" href="../available_tools/lidar_tools.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                    <a href="../available_tools/image_processing_tools_filters.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                

                
                    <a href="../available_tools/lidar_tools.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
                
            </nav>

        </div>

        

        

        

        
        <script src="../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        

    </body>
</html>
