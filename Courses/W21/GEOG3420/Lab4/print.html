<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>GEOG3420 W20 Lab 4</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        
        <link rel="stylesheet" href="css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="intro.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="part1.html"><strong aria-hidden="true">2.</strong> Part 1: Normalized Difference Indices</a></li><li class="chapter-item expanded "><a href="part2.html"><strong aria-hidden="true">3.</strong> Part 2: Multi-spectral Image Classification</a></li><li class="chapter-item expanded "><a href="part3.html"><strong aria-hidden="true">4.</strong> Part 3: Cleaning the Class Map</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">GEOG3420 W20 Lab 4</h1>

                    <div class="right-buttons">
                        
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="geog3420-remote-sensing-of-the-environment-w21"><a class="header" href="#geog3420-remote-sensing-of-the-environment-w21">GEOG*3420 Remote Sensing of the Environment (W21)</a></h1>
<h2 id="lab-assignment-4"><a class="header" href="#lab-assignment-4"><strong>Lab Assignment 4</strong></a></h2>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p>This lab exercise introduces students to unsupervised image classification using the k-Means and modified k-Means classification algorithms. Students will also learn about the use of band ratios to enhance classification accuracy by reducing scene variation in illumination due to topography.</p>
<h2 id="readings-and-resources"><a class="header" href="#readings-and-resources">Readings and Resources</a></h2>
<p>The following materials, combined with your textbook, can be used as background materials and to help in answering the assignment questions.</p>
<ul>
<li><a href="https://jblindsay.github.io/wbt_book/intro.html">Lindsay, J.B. 2019. The WhiteboxTools User Manual</a></li>
</ul>
<h2 id="before-you-begin"><a class="header" href="#before-you-begin">Before you begin</a></h2>
<p><strong>IMPORTANT INFORMATION</strong>: You will need to download a fresh copy of the latest version of the <a href="https://www.uoguelph.ca/%7Ehydrogeo/WhiteboxTools/index.html">WhiteboxTools</a> library before you begin this assignment. Changes have been made to the library since you completed Lab 2 and use of an older version will likely result in incorrect results. In addition, you will need to download the data associated with this lab assignment from the GEOG*3420 CourseLink site. These data, as usual, are quite large and you will need to consider data storage solutions (e.g. a dedicated USB memory stick for the course).</p>
<h2 id="what-you-need-to-hand-in"><a class="header" href="#what-you-need-to-hand-in">What you need to hand in</a></h2>
<p>You will hand in a printed report summarizing the answer to each of the questions in the following exercise along with the necessary colour images. Notice that you will need to have paid your lab fee to have printing privileges in the Hutt building computer labs.</p>
<h1 id="part-1-normalized-difference-indices-band-ratios"><a class="header" href="#part-1-normalized-difference-indices-band-ratios">Part 1: Normalized Difference Indices (Band Ratios)</a></h1>
<p>The process of dividing the brightness values in one band of a multispectral data set by a second band image is known as <em>Band Ratioing</em>. Ratioing is one of the most common image transformations in remote sensing because:</p>
<ol>
<li>
<p>It can be used to emphasize certain aspects of the shape of the spectral signatures of different land covers, and;</p>
</li>
<li>
<p>It can be used to de-emphasize the effects of variable illumination within a scene.</p>
</li>
</ol>
<p>The first of these characteristics makes band ratioing particularly useful for creating image products that are derived from the original multispectral data set and are suited to identifying specific land-cover types. This is the reason why so many of the remote-sensing based <em>vegetation indices</em> are essentially ratios of two bands. However, it is the second property of band ratios listed above that we are most interested in for this lab. </p>
<p>The purpose of an image classification (see <a href="./part2.html">Part 2</a>) is to identify <em>meaningful</em> land-cover classes within a scene. Differentiating between deciduous and coniferous forest classes is meaningful. It is, however, not particularly meaningful to differentiate between coniferous forest that is situated on a well-illuminated, sun-facing slope versus the in-shadow opposing slope side. However, these two illumination-varying classes areas will have apparently different radiometric properties in a multispectral data set. Band ratio images can be used to lessen the effect of uneven illumination caused by varying topography, based on the assumption that the ratio of two bands for areas of equivalent land-cover type is the same regardless of what direction the slope faces. Ratioing can help to reduce other causes of varying illumination as well, including the shadows cast by clouds.</p>
<p>After you have downloaded the data associated with this lab assignment from the CourseLink page, decompress (unzip) the data into a working directory that you have created to dedicate to this assignment. Open the contents of this folder and examine the files contained within. These data are the 30 m resolution bands, in GeoTIFF image format, of a subsection of a Landsat 8 scene acquired June 21, 2016. These data should contain six bands (i.e. bands 2 through 7) of image data, for an area of Southern Ontario between Kitchener-Waterloo, Cambridge, and Guelph.  If you are unfamiliar with the southern Ontario area, you may also want to explore the area using Google Maps to familiarize yourself with the type of terrain and land-use/land-covers in the area of the image.</p>
<p>We will calculate a number of common <em>normalized difference indices</em>, a type of standardized band ratio, to serve as inputs for a later image classification performed in <a href="./part2.html">Part 2</a> of the lab assignment. Calculate the following image-derived products:</p>
<ol>
<li>
<p>The normalized difference vegetation index: NDVI = (NIR - RED) / (NIR + RED)</p>
</li>
<li>
<p>The normalized difference water index version 1: NDWI1 = (NIR - SWIR1) / (NIR + SWIR1)</p>
</li>
<li>
<p>The normalized difference water index version 2: NDWI2 = (GREEN - NIR) / (GREEN + NIR)</p>
</li>
<li>
<p>The normalized burn ratio: NBR = (NIR - SWIR2) / (NIR + SWIR2)</p>
</li>
<li>
<p>The normalized blue-red ratio: NBRR = (BLUE - RED) / (BLUE + RED)</p>
</li>
</ol>
<blockquote>
<p>For Landsat 8, the spectral designations in the above equations relate to bands in the following way:</p>
<p>BLUE = Band 2</p>
<p>GREEN = Band 3</p>
<p>RED = Band 4</p>
<p>Near infrared (NIR) = Band 5</p>
<p>Shortwave infrared 1 (SWIR1) = Band 6</p>
<p>Shortwave infrared 2 (SWIR2) = Band 7</p>
</blockquote>
<p>Write a script to use the WhiteboxTools' <a href="https://jblindsay.github.io/wbt_book/available_tools/image_processing_tools.html#NormalizedDifferenceRatio"><code>**NormalizedDifferenceRatio**</code></a> tool to create each of the above normalized difference indices. Be sure to clip the distribution tails by 0.5%, and use a correction value of 0.0.</p>
<blockquote>
<p>1.1. Why do you think it is that band ratio, such as the ones described above, are so widely used in remote sensing? What are some of the advantages of using band ratios in analyses compared with raw multispectral image bands? (4 marks)</p>
<p>1.2 Include screenshots of each of the five indices, being sure to label each carefully and indicating the minimum and maximum values of each. (15 marks)</p>
<p>1.3. Include a copy of your Python script used to create the five normalized difference indices. (2 marks)</p>
<p>1.4. Compare each of the five indices to the natural-colour composite image. To what extent was the use of the band-ratioing technique able to lessen the apparent effects of cloud shadows in the image? (2 marks)</p>
</blockquote>
<h1 id="part-2-multi-spectral-image-classification"><a class="header" href="#part-2-multi-spectral-image-classification">Part 2: Multi-spectral Image Classification</a></h1>
<p>Multi-spectral image classification involves two distinct activities. The first activity is the recognition of categories of real-world features in the landscape, e.g. 'deciduous forests'. The second activity in all multi-spectral classifications involves labeling pixels within an image data set. With <strong>supervised classification</strong> methods, the user first identifies real-world land-covers, examines the images to find training areas to typify the 'spectral signatures' of these features and then uses the signatures to label all of the remaining pixels in the scene. <strong>Unsupervised classification</strong> techniques rely on statistical clustering methods (e.g. k-Means clustering) to find groups, or clusters, of similar pixels with respect to their spectral properties. After this initial clustering phase, the user then has the task of relating the statistically defined spectral classes to real-world land-covers. Both approaches to image classification require a substantial amount of human effort and judgement to identify land-covers within the image scene. The difference is that with supervised classification techniques this human component occurs early on in the process, while unsupervised classification methods require effort after the automated classification step in determining the physical meaning of each statistically defined cluster. Generally, supervised classification techniques are preferred because the image analyst has greater control over the classification (e.g. I may know that I want to classify <em>water</em>, <em>urban</em>, <em>forest</em>, <em>agriculture</em>), whereas, the analyst has very little control over the clusters that are created by unsupervised methods. However, unsupervised classification techniques are useful as an initial exploratory tool and when the analyst is unfamiliar with data or the landscape being analyzed.</p>
<h2 id="k-means-clustering-for-unsupervised-image-classification"><a class="header" href="#k-means-clustering-for-unsupervised-image-classification">k-Means Clustering For Unsupervised Image Classification</a></h2>
<blockquote>
<p>Unsupervised classification is described in the course text:</p>
<p><strong>Readings:</strong> Mather and Koch (2011), Chapter 8 Classification, <em>Computer Processing of Remotely-Sensed Images</em>, pp 233-240. </p>
<p>It is strongly recommended that you do this reading before continuing.</p>
</blockquote>
<p>Use WhiteboxTools' <a href="https://jblindsay.github.io/wbt_book/available_tools/image_processing_tools.html#KMeansClustering">KMeansClustering</a> tool to perform a k-Means unsupervised classification on the five normalized difference indices (NDIs) calculated in <a href="./part1">Part 1</a>. Mather and Koch (2011) describe how this classification technique works in detail in Chapter 8. Enter the five NDIs as the input images. Call the output image <code>kmeans_class.tif</code> and the output HTML report <code>kmeans_report.html</code>. Set the <em>number of clusters</em> (<code>--classes</code>) to 12, the <em>maximum number of iterations</em> (<code>--max_iterations</code>) to 20. The <em>percent class change threshold</em> (<code>--class_change</code>), which determines when the operation converges, can be set to 1%. Initialize the cluster locations on the diagonal (<code>--initialize=&quot;diagonal&quot;</code>). This will place the initial cluster locations randomly along the multi-dimensional diagonal line. Importantly, this means that each run of this tool will result in a unique output. The <em>minimum class size</em> (<code>--min_class_size</code>) should be 1000.</p>
<p>When the tool is complete, several outputs will be created. In addition to the output class image, there will be a classification report. This report includes tables for: 1) the number of pixels in each spectral class, 2) the cluster centroid vectors (i.e. the center point for the class in spectral space), and 3) the the Euclidean distance in spectral space between each cluster centroid and the other clusters. This last table can be useful information for identifying classes that are similar and are candidates for further clustering, i.e. reclassification. Lastly, the report includes a <em>Convergence Plot</em> which describes the number of pixels in the scene that were re-assigned to different clusters with each iteration of the k-mean clustering operation.</p>
<blockquote>
<p>2.1. Include the classification report in your final hand-in. (1 mark) </p>
<p>2.2. Based on the <em>Cluster Centroid Distance Analysis</em> table, are there any groups of the 12 clusters that can potentially be joined due to similarity? (2 mark)</p>
<p>2.3. Did the clustering procedure require fewer than the maximum number of iterations to reach convergence, i.e. to reach a point of stability where less than the required 1% of pixels were re-assigned to different clusters? That is, how many iterations were required before clusters became stable? (1 mark)</p>
</blockquote>
<p>The classification image that results from running the tool is far from a work of art. In fact, it’s likely down-right ugly (it does have a great deal of inside beauty though!). This is because each of the spectral classes that have been identified have been assigned a random colour in the classification image. And because there was likely quite a few classes in this image, the image appears rather chaotic.</p>
<blockquote>
<p>2.4. Relate each of the spectral classes (i.e. the statistically defined clusters) that were identified by the unsupervised classification technique into information classes and present this information in a table (12 marks). Information classes are categories of ground cover. For example, information classes may include categories such as: shallow water, cloud, cloud shadow, agricultural, urban-commercial, urban-residential, forest, forest in-shadow, etc. These classes can be as specific as are needed. </p>
</blockquote>
<p>Note, relating spectral classes to information classes can be a challenging and time-consuming task, so be sure to give yourself enough time. Here are some tips:Some spectral classes will correspond to obvious information classes, but others will not. Some may be really difficult to figure out.</p>
<ol>
<li>
<p>Overlay the true-colour composite on the classification image. Then you can zoom into various features and toggle between the two images.</p>
</li>
<li>
<p>Several classes are likely associated with mixed pixels, i.e. pixels that contain a mixture of ground cover in them. For example, given how narrow roads are relative to the spatial resolution of the imagery, there are likely a lot of pixel that are a mixture of road and road-side vegetation. As such, there may be spectral classes that are associated with the ‘pure’ spectral pattern of certain land-covers, and other related spectral classes that are associated with mixtures. The dendrogram can help you to discern this.</p>
</li>
<li>
<p>Some spectral classes my be associated with more than one information class and some information classes may overlap with more than one spectral class.</p>
</li>
<li>
<p>Some information classes are more spectrally variable than others. For example, residential areas contain a wide mixture of land-covers compared to the more homogenous spectral characteristics that you would expect to find in a forested area. An 'agricultural' class may be impossible in areas where there is a great deal of variation in crop type.</p>
</li>
<li>
<p>Use the <em>Cluster Centroid Distance Analysis</em> table to help you identify similar spectral classes; they are likely to have similar information classes. These are also candidate classes for further merging/reclassing. For example, if there are spectral classes associated with three different crop types, these could be classed into one 'agricultural' class.</p>
</li>
</ol>
<p>Now perform a second k-means clustering operation, using the raw band images and the same input parameters. When it has completed, display the classification image and compare it to the classification that was based on the normalized difference indices.</p>
<blockquote>
<p>2.5. Examining the areas of cloud shadow and comparing between the two classification outputs, to what extent did the use of band-ratios as inputs in the original clustering operation reduce the impact of the variable illumination in these cloud obscured sites? (2 marks)</p>
</blockquote>
<h1 id="part-3-cleaning-the-class-map"><a class="header" href="#part-3-cleaning-the-class-map">Part 3: Cleaning the Class Map</a></h1>
<p>The class image derived from the classification procedure in Part 2 is likely very 'messy'. That is, it may contain several very small class groupings (objects), which contribute to a noisy appearance. In lecture we learned that a <a href="https://jblindsay.github.io/wbt_book/available_tools/image_processing_tools_filters.html#MajorityFilter"><strong>Majority filter</strong></a> can be used to simplify and clean-up a categorical raster. Apply the Majority filter to your class map to simplify the classification output. Experiment with different filter sizes (although square filters should be used, e.g. 3x3, 5x5, 7x7, etc.) until you are happy with the output.</p>
<blockquote>
<p>3.1. Include your final filtered class image with your final report. (1 mark)</p>
<p>3.2. Why is class image simplification sometimes necessary? (2 marks)</p>
<p>3.3. Describe the impact of varying the filter size on the output raster. What filter size did you settle on and why? What are problems are encountered with the classification image when the filter size is set to too large a value? (4 marks)</p>
<p>3.4. Other than using a majority filter, can you suggest another way that the outputs of image classification operations are commonly simplified? (1 mark)</p>
</blockquote>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
