{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0ca6540-c5b4-4606-8cba-be9a8cd612ea",
   "metadata": {},
   "source": [
    "# Using Whitebox Workflows (WbW) to process lidar data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af1186d-ef85-4cd5-b12e-d3b76356fa6e",
   "metadata": {},
   "source": [
    "You may download a copy of the raw [Jupyter Notebooks](https://jupyter.org/) file (`*.ipynb`) [from here](https://github.com/jblindsay/jblindsay.github.io/blob/master/WhiteboxTutorials/WbW_tutorials/WbW_lidar.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77e8acd-376f-4be6-a62d-df0518474288",
   "metadata": {},
   "source": [
    "## Setting up the WbW environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dafc472-5141-4745-8328-ad179554c66f",
   "metadata": {},
   "source": [
    "First, let's install the WbW library using pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1af47ab-5d23-4ebe-bf9f-7e5db73f6248",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install whitebox-workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b345fd33-cc6c-42a6-bb7a-d7f7a4e61ef5",
   "metadata": {},
   "source": [
    "Or if you have it installed already but need to update to the latest version, you may do so with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c70c405-e7e2-4bef-8be6-8f39ef55b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install whitebox-workflows -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9cfd91-a27f-4241-a47a-1944bd4f9b4b",
   "metadata": {},
   "source": [
    "As you're writing a WbW script, you may learn about various functions and get help with WbW idioms from the [Whitebox Workflows for Python user manual](https://www.whiteboxgeo.com/manual/wbw-user-manual/book/preface.html).\n",
    "\n",
    "Each WbW script must begin by importing the `WbEnvrionment` class from the `whitebox_workflows` library and setting up a `WbEnvironment` object. Also note that we are setting the `wbe.verbose` variable to `True`, which will allow the various `wbe` functions to output to the terminal. That way we can receive updates as things are happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853484c6-1411-47d2-9bcb-f8e804c971e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from whitebox_workflows import WbEnvironment, download_sample_data\n",
    "\n",
    "wbe = WbEnvironment() # This will use the standard tier of WbW\n",
    "wbe.verbose = True\n",
    "print(wbe.version()) # Print the version number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0719f44-07dc-432f-b5db-db917a9366b9",
   "metadata": {},
   "source": [
    "Let's create a new script to download some sample data. Here we'll grab the 'Kitchener_lidar' lidar dataset. The script below will download the data for us, assign the directory to which these data are downloaded to the `WbEnvironment` working directory and lastly print this location so we can know where the data are being stored. Notice that it may take a few minutes to download the data. In the event that the download takes more than a few minutes, the connection may timeout and you will receive an error. If this should happen, you may download the dataset directly [from here](http://www.whiteboxgeo.com/sample_data/Kitchener_lidar.zip) but you will need to update the `wbe.working_directory` to your download folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547a04c1-e504-4537-9378-a056478288e2",
   "metadata": {},
   "source": [
    "## Working with lidar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2fa68f-b21a-4e93-b2c6-03b50277758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = download_sample_data('Kitchener_lidar')\n",
    "wbe.working_directory = data_dir\n",
    "print(f'Data have been stored in: {wbe.working_directory}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73abec5d-e615-4756-9a1f-c88dcef865d8",
   "metadata": {},
   "source": [
    "Let's read in the lidar (LAZ) file contained in that download directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ccec87-f6b7-48c5-9b5c-b0c4b86955a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar = wbe.read_lidar('Kitchener_lidar.laz')\n",
    "print(f\"There are {lidar.header.number_of_points} points in the lidar dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0994c47-e3d5-4c58-840c-2433a5763709",
   "metadata": {},
   "source": [
    "Let's get more information about this lidar tile using the [`lidar_info`](https://www.whiteboxgeo.com/manual/wbw-user-manual/book/tool_help.html#lidar_info) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff55889-a979-4e56-9241-f2c4772cd518",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbe.lidar_info(lidar, output_html_file='tile_info.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0bf4a6-05c1-4a16-a06a-502027e0c3a3",
   "metadata": {},
   "source": [
    "Now let's get some information about the distribution of points within this tile. Note that if we don't specify the `input_lidar` parameter in the function below, it'll just run the function on every lidar tile (LAS, LAZ) found in the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa9823b-e900-4739-bce7-6418c7e5150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = wbe.lidar_point_stats(\n",
    "    input_lidar = lidar, \n",
    "    cell_size = 1.0, \n",
    "    num_points = True, \n",
    "    num_pulses = True, \n",
    "    avg_points_per_pulse = True, \n",
    "    z_range = True, \n",
    "    intensity_range = False, \n",
    "    predominant_class = False\n",
    ")\n",
    "\n",
    "# Save the newly created outputs\n",
    "wbe.write_raster(outputs[0], 'num_points.tif', compress=True)\n",
    "wbe.write_raster(outputs[1], 'num_pulses.tif', compress=True)\n",
    "wbe.write_raster(outputs[2], 'avg_points_per_pulse.tif', compress=True)\n",
    "wbe.write_raster(outputs[3], 'z_range.tif', compress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e955a445-cf1a-4940-aa1b-e026dc75668f",
   "metadata": {},
   "source": [
    "Let's measure point density of last/only return points that aren't classified noise..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171309d8-00c2-4ff4-b603-857f9a191a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_density = wbe.lidar_point_density(\n",
    "    input_lidar = lidar, \n",
    "    returns_included = \"last\", \n",
    "    cell_size = 1.0, \n",
    "    search_radius = 2.5, \n",
    "    excluded_classes = [7, 18] # exclude classified noise points  \n",
    ")\n",
    "wbe.write_raster(pt_density, 'pt_density.tif', compress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5101c138-bdec-4451-bbdb-565e29977816",
   "metadata": {},
   "source": [
    "Some of the following operations are contained within the Whitebox Workflows Professional (WbW-Pro) tier of the WbW library. To use these functions we need to have a valid license. Here I'm creating a new instance of a WbEnvironment that uses a floating license ID (a temporary one I'm using for this tutorial) to access the WbW-Pro functions. We **must be sure to check in this floating license after we're done using it**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba167998-8d55-4b46-988b-12d87210c2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbe = WbEnvironment('wbw-tutorial') # This floating license ID will be valid for another 2 weeks.\n",
    "wbe.verbose = False\n",
    "wbe.working_directory = data_dir\n",
    "print(wbe.working_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a57c3ff-84cf-42ea-9a06-685731769bd5",
   "metadata": {},
   "source": [
    "Adding RGB values to the points based on their point returns (first, intermediate, last, only) can be useful for quality control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d43b1b4-8a97-47eb-9d48-0c323360c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_ret_colourized = wbe.colourize_based_on_point_returns(\n",
    "    input_lidar = lidar, \n",
    "    intensity_blending_amount = 50.0\n",
    ")\n",
    "\n",
    "wbe.write_lidar(pt_ret_colourized, 'pt_ret_colourized.las') # Saved as a LAS instead of LAZ so I can more easily visualize it.\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6eea86-2595-4dca-83d0-0d6a52953f7e",
   "metadata": {},
   "source": [
    "Once the operation above is complete, you can visualize the resulting `pt_ret_colourized.las` file in any point cloud viewing software. I recommend using [plas.io](https://plas.io) for something quick and easy. Set the colourization to RGB and turn the intensity blending down. \n",
    "\n",
    "Two of the most powerful functions for manipulating lidar point clouds include: \n",
    "\n",
    "- [filter_lidar](https://www.whiteboxgeo.com/manual/wbw-user-manual/book/tool_help_wbwpro.html#filter_lidar)\n",
    "- [modify_lidar](https://www.whiteboxgeo.com/manual/wbw-user-manual/book/tool_help_wbwpro.html#modify_lidar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f48b23c-a078-4c8e-b9d3-3ad0c0069d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_lidar = wbe.filter_lidar(\n",
    "    statement = '!is_noise && is_late && class==2 && dist_to_pt(mid_x, mid_y)<250.0', \n",
    "    input_lidar = lidar\n",
    ")\n",
    "\n",
    "wbe.write_lidar(filtered_lidar, 'filtered_lidar.las')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282936c7-0b8f-40eb-b9c9-6520a2a81411",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_lidar = wbe.modify_lidar(\n",
    "    statement = 'rgb = if(is_late && class==2 && dist(xy, (mid_x, mid_y))<250.0, (255,0,0), (0,255,0))', \n",
    "    input_lidar = lidar\n",
    ")\n",
    "\n",
    "wbe.write_lidar(modified_lidar, 'modified_lidar.las')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3a68b4-f5ff-4289-ab81-337cc9f318a0",
   "metadata": {},
   "source": [
    "As we saw earlier, this point cloud already has ground points classified. However, let's classify them using WbW-Pro's `improved_ground_point_filter` function just as a demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf03b362-a1e1-46d4-b503-3101a2a18725",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_classified = wbe.improved_ground_point_filter(\n",
    "    input = lidar, \n",
    "    block_size = 1.5, \n",
    "    max_building_size = 250.0, \n",
    "    slope_threshold = 15.0, \n",
    "    elev_threshold = 0.15, \n",
    "    classify = True, \n",
    "    preserve_classes = True\n",
    ")\n",
    "\n",
    "# Let's render the point classes using RGB values for visualization\n",
    "lidar_classified = wbe.colourize_based_on_class(\n",
    "    input_lidar = lidar_classified, \n",
    "    intensity_blending_amount = 50.0, \n",
    "    clr_str = '1: (0, 128, 0)'\n",
    ")\n",
    "\n",
    "wbe.write_lidar(lidar_classified, 'lidar_classified.las')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae76972a-8b3f-4407-8a9f-08f29b465c6a",
   "metadata": {},
   "source": [
    "We can perform a more fullsome point-cloud classification too, but it's much slower..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcfc7f8-8f3b-4007-9283-afe3b7ed416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_classified = wbe.classify_lidar(\n",
    "    input_lidar = lidar, \n",
    "    search_radius = 1.5, \n",
    "    grd_threshold = 0.1, \n",
    "    oto_threshold = 1.0, \n",
    "    linearity_threshold = 0.5, \n",
    "    planarity_threshold = 0.85, \n",
    "    num_iter = 30, \n",
    "    facade_threshold = 0.5\n",
    ")\n",
    "\n",
    "# Let's render the point classes using RGB values for visualization\n",
    "lidar_classified = wbe.colourize_based_on_class(\n",
    "    input_lidar = lidar_classified, \n",
    "    intensity_blending_amount = 50.0\n",
    ")\n",
    "\n",
    "wbe.write_lidar(lidar_classified, 'lidar_full_classified.las')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a514938-535c-413b-a3ae-34d54432de0e",
   "metadata": {},
   "source": [
    "Let's extract [eigenvalue features](https://www.whiteboxgeo.com/manual/wbw-user-manual/book/tool_help_wbwpro.html#lidar_eigenvalue_features) for each point in the cloud. These are a series of point metrics that can be used to describe the neighbourhood surrounding each point. Is the neighbourhood linear, planar, or a volume?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca28d4f-110c-4821-8c9a-88d64b6d2b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create a '*.eigen' file that has the same name as the input lidar file.\n",
    "# These could be very useful for deep-learning based point classification applications.\n",
    "# This may be a slow-running application depending on your computer power.\n",
    "wbe.lidar_eigenvalue_features(\n",
    "    input_lidar = lidar, \n",
    "    num_neighbours = 150, \n",
    "    search_radius = 10.0\n",
    ")\n",
    "\n",
    "# To get a sense of what these data look like, map some of the eigenvalue features\n",
    "# onto the point RGB values. This is just for visualization. In reality, you'd likely\n",
    "# want to read the *.eigen file into Python using NumPy. See the docs for more info.\n",
    "eigen_lidar = wbe.modify_lidar(\n",
    "    statement = 'rgb=(int(linearity*255), int(planarity*255), int(sphericity*255))', \n",
    "    input_lidar = lidar\n",
    ")\n",
    "\n",
    "wbe.write_lidar(eigen_lidar, 'eigen_lidar.las')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41846643-3545-4916-87b2-d05553b0127a",
   "metadata": {},
   "source": [
    "Create a digital surface model from the point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613a50be-6b8a-4611-b5f3-7bad987041c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm = wbe.lidar_digital_surface_model(\n",
    "    input_lidar = lidar, \n",
    "    cell_size = 1.0, \n",
    "    search_radius = 0.5\n",
    ")\n",
    "wbe.write_raster(dsm, 'dsm.tif', compress=True)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b8f3b3-6998-467d-878f-79f73e201614",
   "metadata": {},
   "source": [
    "Okay, now let's create a digital terrain model (DTM), i.e. a bare-earth DEM based on our classified ground points. Here we're using TINing, but there are other interpolators available too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ddd1ef-652d-4210-ac1b-549c2f057b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = wbe.lidar_tin_gridding(\n",
    "    input_lidar = lidar_classified, \n",
    "    interpolation_parameter = \"elevation\", \n",
    "    returns_included = \"all\", \n",
    "    cell_size = 1.0, \n",
    "    excluded_classes = [1,7,17,18], \n",
    ")\n",
    "wbe.write_raster(dtm, 'dtm.tif', compress=True)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9510eb-6f9d-4b81-983b-3c0007339a23",
   "metadata": {},
   "source": [
    "How about a DEM of difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ff497-9429-4c7a-910d-1537c5f577b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dod = dsm - dtm # You can use typical math ops with Whitebox rasters\n",
    "wbe.write_raster(dod, 'DoD.tif', compress=True)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7517fa-bddf-4fc3-8a57-1968935fcac1",
   "metadata": {},
   "source": [
    "## Working with DTM data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8a7fa4-824e-4891-88bf-47f4a28937fb",
   "metadata": {},
   "source": [
    "Let's download a different data set to work with now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f24532f-fa87-4b6e-a2e2-3b0274aba889",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbe.working_directory = download_sample_data('mill_brook')\n",
    "print(f'Data have been stored in: {wbe.working_directory}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419bd24f-c932-41e7-ab67-f043fed5243a",
   "metadata": {},
   "source": [
    "Create a raster DTM from the lidar point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf58dc5-d15c-48e0-952b-1ba8dd132b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbe.verbose = False\n",
    "\n",
    "lidar = wbe.read_lidar('mill_brook.laz')\n",
    "\n",
    "dtm = wbe.lidar_tin_gridding(\n",
    "    input_lidar = lidar, \n",
    "    interpolation_parameter = \"elevation\", \n",
    "    returns_included = \"all\", \n",
    "    cell_size = 1.0, \n",
    "    excluded_classes = [1,7,18], \n",
    ")\n",
    "wbe.write_raster(dtm, 'dtm.tif', compress=True)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6124ab-99a4-401f-a9de-beb4df4f24e7",
   "metadata": {},
   "source": [
    "Let's create a hillshade image for this DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d3456f-3192-4fcc-981b-950a660e26c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a hillshade image\n",
    "hillshade = wbe.multidirectional_hillshade(dtm)\n",
    "wbe.write_raster(hillshade, 'hillshade.tif', compress=True)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413900e9-4f1a-4058-a0be-d76fdbe6f7ff",
   "metadata": {},
   "source": [
    "Smooth the DTM. This step normally takes some experimentation to get the parameters right, which is why\n",
    "why I save the raw DEM/hillshade. Comparison on the hillshade images allows me to tweak the parameters\n",
    "until I find that the output DEM has the appropriate level of smoothing that I need for my application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1921845e-b9c6-47da-ac8f-313dbd88d62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_smoothed = wbe.feature_preserving_smoothing(dtm, filter_size=11, normal_diff_threshold=25.0, iterations=5)\n",
    "wbe.write_raster(dtm_smoothed, 'dtm_smoothed.tif', compress=False) \n",
    "\n",
    "# We'll need to save the hillshade image to compare with the hillshade from the raw DEM to\n",
    "# evaluate whether the smoothing was sufficient.\n",
    "hs = wbe.multidirectional_hillshade(dtm_smoothed)\n",
    "wbe.write_raster(hs, 'hillshade_smoothed.tif', compress=False) \n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdcc0e9-b37a-4dfa-9081-8ab7dc27100f",
   "metadata": {},
   "source": [
    "Derive a contour coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2c07b3-aead-4714-ba0e-6648db066e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours = wbe.contours_from_raster(dtm_smoothed, contour_interval=10.0)\n",
    "wbe.write_vector(contours, 'contours.shp')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7158c4ef-7228-435e-b409-4f6a3a34777f",
   "metadata": {},
   "source": [
    "And how about breaklines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6366a549-3cf4-4b52-88e6-e1fcf6616bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "breaklines = wbe.breakline_mapping(dtm_smoothed, threshold=3.0, min_length=3)\n",
    "wbe.write_vector(breaklines, 'breaklines.shp')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da13d11-668c-4032-b7a3-bb78e8595762",
   "metadata": {},
   "source": [
    "## Geomorphometry from DTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca4ba25-4f91-4e64-9d9e-70d30050e172",
   "metadata": {},
   "source": [
    "Now let's extract some common land-surface parameters (LSPs), the basic building blocks of a geomorphometric analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416132e9-b48e-4829-8e59-40b3b14d2ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbe.verbose = False\n",
    "\n",
    "# Slope and aspect are two of the most common LSPs. Notice that we're combining the writing of the\n",
    "# output raster and the running of the function in one line. We won't reuse the raster objects\n",
    "# created by each function and are only saving them to file and so this makes sense.\n",
    "wbe.write_raster(wbe.slope(dtm_smoothed, units=\"degrees\"), 'slope.tif', compress=True)\n",
    "wbe.write_raster(wbe.aspect(dtm_smoothed), 'aspect.tif', compress=True)\n",
    "\n",
    "# Surface curvatures describe surface shape\n",
    "wbe.write_raster(wbe.profile_curvature(dtm_smoothed, log_transform=True), 'prof_curv.tif', compress=True)\n",
    "wbe.write_raster(wbe.tangential_curvature(dtm_smoothed, log_transform=True), 'tan_curv.tif', compress=True)\n",
    "wbe.write_raster(wbe.plan_curvature(dtm_smoothed, log_transform=True), 'plan_curv.tif', compress=True)\n",
    "wbe.write_raster(wbe.minimal_curvature(dtm_smoothed, log_transform=True), 'min_curv.tif', compress=True)\n",
    "wbe.write_raster(wbe.maximal_curvature(dtm_smoothed, log_transform=True), 'max_curv.tif', compress=True)\n",
    "wbe.write_raster(wbe.mean_curvature(dtm_smoothed, log_transform=True), 'mean_curv.tif', compress=True)\n",
    "wbe.write_raster(wbe.gaussian_curvature(dtm_smoothed, log_transform=True), 'gauss_curv.tif', compress=True)\n",
    "wbe.write_raster(wbe.total_curvature(dtm_smoothed, log_transform=True), 'total_curv.tif', compress=True)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7c32b3-542e-43da-9a21-890708b5578d",
   "metadata": {},
   "source": [
    "The following advanced curvatures are found in WbW-Pro. To run the script below, you'll **need a valid WbW-Pro license**, otherwise you will receive an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b43c5ad-c31b-404d-889e-d1f5b79d2726",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbe.write_raster(wbe.accumulation_curvature(dtm_smoothed, log_transform=True), 'accum_curv.tif', compress=True)\n",
    "wbe.write_raster(wbe.curvedness(dtm_smoothed, log_transform=True), 'curvedness.tif', compress=True)\n",
    "wbe.write_raster(wbe.difference_curvature(dtm_smoothed, log_transform=True), 'diff_curv.tif', compress=True)\n",
    "wbe.write_raster(wbe.generating_function(dtm_smoothed, log_transform=True), 'generating_function.tif', compress=True)\n",
    "wbe.write_raster(wbe.horizontal_excess_curvature(dtm_smoothed, log_transform=True), 'horiz_excess_curv.tif', compress=True)\n",
    "wbe.write_raster(wbe.ring_curvature(dtm_smoothed, log_transform=True), 'ring_curv.tif', compress=True)\n",
    "wbe.write_raster(wbe.rotor(dtm_smoothed, log_transform=True), 'rotor.tif', compress=True)\n",
    "wbe.write_raster(wbe.shape_index(dtm_smoothed), 'shape_index.tif', compress=True)\n",
    "wbe.write_raster(wbe.unsphericity(dtm_smoothed, log_transform=True), 'unsphericity.tif', compress=True)\n",
    "wbe.write_raster(wbe.vertical_excess_curvature(dtm_smoothed, log_transform=True), 'vertical_excess_curv.tif', compress=True)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d8fa1e-c6b7-4dfa-87a9-1f4acf3035bb",
   "metadata": {},
   "source": [
    "Measures of local topographic position (LTP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d767a712-33eb-4a2a-a77b-92650699ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbe.write_raster(\n",
    "    wbe.elevation_percentile(\n",
    "        dtm_smoothed, \n",
    "        filter_size_x = 51, \n",
    "        filter_size_y = 51, \n",
    "        sig_digits = 3\n",
    "    ), \n",
    "    'elev_percentile.tif', \n",
    "    compress=True\n",
    ")\n",
    "\n",
    "wbe.write_raster(\n",
    "    wbe.difference_from_mean_elevation(\n",
    "        dtm_smoothed, \n",
    "        filter_size_x = 51, \n",
    "        filter_size_y = 51\n",
    "    ), \n",
    "    'dev.tif', \n",
    "    compress=True\n",
    ")\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ee8185-28c0-41dc-bd92-ce4bcd42ec83",
   "metadata": {},
   "source": [
    "The following LSPs can be used to characterize surface roughness and topographic complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93023ea-2c15-4839-8d32-5b09a4f99fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbe.write_raster(wbe.circular_variance_of_aspect(dtm_smoothed, filter_size = 21), 'circular_variance_of_aspect.tif', compress=True)\n",
    "wbe.write_raster(wbe.edge_density(dtm_smoothed, filter_size=21, normal_diff_threshold=5.0), 'edge_density.tif', compress=True)\n",
    "wbe.write_raster(wbe.spherical_std_dev_of_normals(dtm_smoothed, filter_size = 21), 'spherical_sd_norms.tif', compress=True)\n",
    "wbe.write_raster(wbe.standard_deviation_of_slope(dtm_smoothed, filter_size = 21), 'stdev_slope.tif', compress=True)\n",
    "wbe.write_raster(wbe.surface_area_ratio(dtm_smoothed), 'surface_area_ratio.tif', compress=True)\n",
    "wbe.write_raster(wbe.ruggedness_index(dtm_smoothed), 'ruggedness_index.tif', compress=True)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b83f9e-c813-49ec-aad7-2311b0f4dc40",
   "metadata": {},
   "source": [
    "## Spatial hydrology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46127c27-ef03-4c52-a7d2-f35abc2022a7",
   "metadata": {},
   "source": [
    "Now let's do a bit of hydrological processing of the data, including extracting a stream network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce59c3e-6bbd-4d5f-aa49-860f2e5e9b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math # We'll use the log function below\n",
    "\n",
    "# Remove the depressions, first by breaching the depressions using a max dist so that it doesn't\n",
    "# carve excessively long trenches for very deep pits, and then filling the remaining depressions\n",
    "dem_no_deps = wbe.breach_depressions_least_cost(dtm_smoothed, flat_increment=0.001, max_dist=100) # Change the max dist parameter as appropriate for your DEM\n",
    "dem_no_deps = wbe.fill_depressions(dem_no_deps, flat_increment=0.001)\n",
    "\n",
    "# Perform a flow-accumulation operation. Here I'm using the Qin (2007) multiple flow direction algorithm\n",
    "# but there are many other options available, including D-infinity.\n",
    "#\n",
    "# Stream channels are usually identified as areas of relatively high flow accumulation and are mapped by thresholding\n",
    "# flow accumulation values. Let's choose a threshold value.\n",
    "channel_threshold = 25000.0\n",
    "flow_accum = wbe.qin_flow_accumulation(dem_no_deps, out_type='cells', convergence_threshold=channel_threshold, log_transform=True)\n",
    "wbe.write_raster(flow_accum, 'qin_flow_accum.tif')\n",
    "\n",
    "# Map the streams by thresholding the flow accum raster, using the same convergence threshold used above. This way\n",
    "# we can be assured that the streams are single-cell wide D8 representation, which is needed for any stream\n",
    "# network analysis operations.\n",
    "streams = flow_accum > math.log(channel_threshold)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1372d14-d3f7-4fc8-9955-f01835d1cfb8",
   "metadata": {},
   "source": [
    "Decreasing the value of `channel_threshold` will result in a more extensive network of stream channels and increasing it will result in a less extensive network. The channel threshold of 25000 (in grid cells) has been selected simply by examining the values of flow accumulation within the `qin_flow_accum.tif` file near the headwaters of the visible stream channels in the hillshade image. There will, of course, be variation in this value and it may require some refining to get a reasonable value that performs well throughout. In fact, geomorphologists often use more sophisticated methods, usually involving slope and sometimes other factors, to select a channelization threshold. Experiment with the value of `channel_threshold` to see how the stream network is impacted by this value.\n",
    "\n",
    "Now let's map the areas draining to an outlet point and to various parts of the stream network..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c1b0e7-180f-4148-9e5a-bf75d87a86b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's extract the watershed for a specific outlet point\n",
    "outlet = wbe.read_vector('outlet.shp') # This is a vector point that was included when we downloaded the `mill_brook` dataset.\n",
    "\n",
    "# Make sure that the outlet is positioned along the stream\n",
    "outlet = wbe.jenson_snap_pour_points(outlet, streams, 5.0)\n",
    "\n",
    "# We need a d8-pointer raster to be able to route flow through the network\n",
    "d8_pntr = wbe.d8_pointer(dem_no_deps)\n",
    "\n",
    "# Extract the outlet's watershed\n",
    "watershed = wbe.watershed(d8_pointer=d8_pntr, pour_points=outlet)\n",
    "\n",
    "# Vectorize the watershed polygon for visualization\n",
    "watershed_vec = wbe.raster_to_vector_polygons(watershed)\n",
    "# Smooth the watershed map for visualization\n",
    "watershed_vec = wbe.smooth_vectors(watershed_vec, filter_size=5) \n",
    "wbe.write_vector(watershed_vec, 'watershed.shp')\n",
    "\n",
    "# Now, we only want the streams inside the watershed\n",
    "streams = streams * watershed # Notice that we can treat the rasters like any other Python variable in a math equation.\n",
    "\n",
    "# Perform a stream network analysis on the stream vector\n",
    "streams_vec = wbe.raster_streams_to_vector(streams, d8_pntr)\n",
    "streams_vec, tmp1, tmp2, tmp3 = wbe.vector_stream_network_analysis(streams_vec, dem_no_deps) # We only want the streams output\n",
    "wbe.write_vector(streams_vec, 'streams.shp')\n",
    "\n",
    "# Extract all of the watersheds, draining to each outlet on the edge of the DEM using the 'basins' function.\n",
    "basins = wbe.basins(d8_pntr)\n",
    "wbe.write_raster(basins, 'basins.tif')\n",
    "\n",
    "# How about extracting subcatchments, i.e. the areas draining directly to each link in the stream network?\n",
    "subcatchments = wbe.subbasins(d8_pntr, streams)\n",
    "wbe.write_raster(subcatchments, 'subcatchments.tif')\n",
    "\n",
    "# Or perhaps map Strahler basins, i.e. the areas draining to Strahler order 1, 2, 3, etc. streams...\n",
    "strahler_basins = wbe.strahler_order_basins(d8_pointer=d8_pntr, streams=streams)\n",
    "wbe.write_raster(strahler_basins, 'strahler_basins.tif')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e48db80-44e9-4a73-b3d6-8514b3b5cbe2",
   "metadata": {},
   "source": [
    "Let's calculate depth-to-water index, useful for flood mapping applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1c3f32-3c6c-40cc-aa2b-d2506427b290",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_to_water = wbe.depth_to_water(\n",
    "    dem = dem_no_deps, \n",
    "    streams = streams_vec\n",
    ")\n",
    "wbe.write_raster(depth_to_water, 'depth_to_water.tif')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d26cf-2f89-4cae-818d-6b5aa3276537",
   "metadata": {},
   "source": [
    "## Wrapping things up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec0ddbe-b4f0-4357-b352-1a36a9d3fb4a",
   "metadata": {},
   "source": [
    "Don't forget to check in your WbW-Pro floating license or it won't be available later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c2a9ab-c883-42f8-810b-808121109ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbe.check_in_license('wbw-tutorial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2add9ccd-3d5a-4614-a22e-7f1eb012e979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
